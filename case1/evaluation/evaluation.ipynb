{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('../data/data_merged.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map model answer to answer options for questions with answer options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/nils/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/nils/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize the BERT model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def parse_options(options_str):\n",
    "    return options_str.strip('[]').split(', ')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercase, remove punctuation, and tokenize\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def extract_and_compare(row):\n",
    "    if pd.notna(row['options']):\n",
    "        # Case 1: Pre-defined options\n",
    "        options = parse_options(row['options'])\n",
    "        # switch to model_answer_us for american version\n",
    "        model_answer = 'model_answer_us'\n",
    "        preprocessed_answer = preprocess_text(row[model_answer])\n",
    "        preprocessed_options = [preprocess_text(option) for option in options]\n",
    "\n",
    "        # Use BERT embeddings for semantic similarity\n",
    "        answer_embedding = model.encode(preprocessed_answer)\n",
    "        option_embeddings = model.encode(preprocessed_options)\n",
    "        similarities = util.pytorch_cos_sim(answer_embedding, option_embeddings)[0]\n",
    "        best_match_index = similarities.argmax().item()\n",
    "\n",
    "        best_match = options[best_match_index].strip()\n",
    "        return best_match\n",
    "    else:\n",
    "        # Case 2: Open-ended\n",
    "        return None\n",
    "#data['model_answer_uk_option_match'] = data.apply(extract_and_compare, axis=1, result_type='expand')\n",
    "data['model_answer_us_option_match'] = data.apply(extract_and_compare, axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of options for later score calculation\n",
    "\n",
    "import ast\n",
    "def parse(options_str):\n",
    "    try:\n",
    "        # Safely evaluate the string as a Python literal (list)\n",
    "        return ast.literal_eval(options_str)\n",
    "    except ValueError:\n",
    "        return []\n",
    "\n",
    "def count_options(options):\n",
    "    # Count the number of options\n",
    "    return len(options)\n",
    "\n",
    "data['#_options'] = data['options'].apply(lambda x: count_options(parse(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_quotes(df, column_name):\n",
    "    # Apply the function to each row in the specified column\n",
    "    df[column_name] = df[column_name].apply(lambda x: x[1:-1] if x and x.startswith(\"'\") and x.endswith(\"'\") else x)\n",
    "    return df\n",
    "\n",
    "# Apply the function to every row in the specified column\n",
    "#data = remove_quotes(data, 'model_answer_us_option_match')\n",
    "#data = remove_quotes(data, 'model_answer_uk_option_match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score for questions with answer options\n",
    "def calculate_score(row):\n",
    "    if row['question type'] in ['Likert Scale', 'Numerical Scale', 'Ordinal Scale'] and row['#_options'] > 2:\n",
    "        ground_truth = row['answer_us']\n",
    "        model_answer = row['model_answer_us_option_match']\n",
    "        options = row['options']\n",
    "\n",
    "        # Normalize the positions of the answers in the options list to a 0-1 range\n",
    "        gt_index = options.index(ground_truth) / (len(options) - 1)\n",
    "        model_index = options.index(model_answer) / (len(options) - 1)\n",
    "\n",
    "        # Calculate the absolute error\n",
    "        error = abs(gt_index - model_index)\n",
    "\n",
    "        # Score can be inversely related to the error (1 - error)\n",
    "        score = 1 - error\n",
    "        return score\n",
    "    else: \n",
    "        return int(row['answer_us'] == row['model_answer_us_option_match'])\n",
    "# Apply the scoring function to each row\n",
    "data['score_us'] = data.apply(calculate_score, axis=1)\n",
    "#data['score_us_neutral'] = data.apply(calculate_score, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>selections</th>\n",
       "      <th>options</th>\n",
       "      <th>source</th>\n",
       "      <th>value_us</th>\n",
       "      <th>value_uk</th>\n",
       "      <th>index_us</th>\n",
       "      <th>index_uk</th>\n",
       "      <th>answer_us</th>\n",
       "      <th>...</th>\n",
       "      <th>overall_score_us</th>\n",
       "      <th>similarity_model_answers_uk_us</th>\n",
       "      <th>similarity_ground_truth_answers_uk_us</th>\n",
       "      <th>model_answer_neutral_option_match</th>\n",
       "      <th>score_us_neutral</th>\n",
       "      <th>score_uk_neurtal</th>\n",
       "      <th>similarity_score_us_vs_neutral</th>\n",
       "      <th>similarity_score_uk_vs_neutral</th>\n",
       "      <th>overall_score_uk_neutral</th>\n",
       "      <th>overall_score_us_neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Which statement comes closer to your own views...</td>\n",
       "      <td>'United States': [0.0, 0.0, 0.54, 0.0, 0.0, 0....</td>\n",
       "      <td>['Using overwhelming military force is the bes...</td>\n",
       "      <td>GAS</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.350254</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Many of the problems facing our country can be...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.907388</td>\n",
       "      <td>0.691288</td>\n",
       "      <td>0.661478</td>\n",
       "      <td>Relying too much on military force to defeat t...</td>\n",
       "      <td>0.907388</td>\n",
       "      <td>0.642040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642040</td>\n",
       "      <td>0.907388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>In your opinion, how strong a sense of Islamic...</td>\n",
       "      <td>'United States': [0.24705882352941178, 0.44705...</td>\n",
       "      <td>['Very strong', 'Fairly strong', 'Not too stro...</td>\n",
       "      <td>GAS</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>0.539326</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Fairly strong</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.891167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Very strong</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Do you think this change in the working condit...</td>\n",
       "      <td>'United States': [0.23157894736842105, 0.76842...</td>\n",
       "      <td>['Largely more connected', 'Other reasons']</td>\n",
       "      <td>GAS</td>\n",
       "      <td>0.768421</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Other reasons</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Other reasons</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Do you think that using military force against...</td>\n",
       "      <td>'United States': [0.22916666666666666, 0.45833...</td>\n",
       "      <td>['Often be justified', 'Sometimes be justified...</td>\n",
       "      <td>GAS</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sometimes be justified</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.923221</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Rarely be justified</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.717391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>On the subject of Iraq, did your country make ...</td>\n",
       "      <td>'United States': [0.5625, 0.4375], 'Britain': ...</td>\n",
       "      <td>['Right decision', 'Wrong decision']</td>\n",
       "      <td>GAS</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.576087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Right decision</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.929168</td>\n",
       "      <td>0.807663</td>\n",
       "      <td>Wrong decision</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           question  \\\n",
       "0           0  Which statement comes closer to your own views...   \n",
       "1           1  In your opinion, how strong a sense of Islamic...   \n",
       "2           2  Do you think this change in the working condit...   \n",
       "3           3  Do you think that using military force against...   \n",
       "4           4  On the subject of Iraq, did your country make ...   \n",
       "\n",
       "                                          selections  \\\n",
       "0  'United States': [0.0, 0.0, 0.54, 0.0, 0.0, 0....   \n",
       "1  'United States': [0.24705882352941178, 0.44705...   \n",
       "2  'United States': [0.23157894736842105, 0.76842...   \n",
       "3  'United States': [0.22916666666666666, 0.45833...   \n",
       "4  'United States': [0.5625, 0.4375], 'Britain': ...   \n",
       "\n",
       "                                             options source  value_us  \\\n",
       "0  ['Using overwhelming military force is the bes...    GAS  0.540000   \n",
       "1  ['Very strong', 'Fairly strong', 'Not too stro...    GAS  0.447059   \n",
       "2        ['Largely more connected', 'Other reasons']    GAS  0.768421   \n",
       "3  ['Often be justified', 'Sometimes be justified...    GAS  0.458333   \n",
       "4               ['Right decision', 'Wrong decision']    GAS  0.562500   \n",
       "\n",
       "   value_uk  index_us  index_uk  \\\n",
       "0  0.350254       2.0       7.0   \n",
       "1  0.539326       1.0       1.0   \n",
       "2  0.645161       1.0       1.0   \n",
       "3  0.510204       1.0       1.0   \n",
       "4  0.576087       0.0       1.0   \n",
       "\n",
       "                                           answer_us  ... overall_score_us  \\\n",
       "0  Many of the problems facing our country can be...  ...         0.907388   \n",
       "1                                      Fairly strong  ...         0.785714   \n",
       "2                                      Other reasons  ...         1.000000   \n",
       "3                             Sometimes be justified  ...         0.717391   \n",
       "4                                     Right decision  ...         0.000000   \n",
       "\n",
       "  similarity_model_answers_uk_us  similarity_ground_truth_answers_uk_us  \\\n",
       "0                       0.691288                               0.661478   \n",
       "1                       0.891167                               1.000000   \n",
       "2                       1.000000                               1.000000   \n",
       "3                       0.923221                               1.000000   \n",
       "4                       0.929168                               0.807663   \n",
       "\n",
       "                   model_answer_neutral_option_match score_us_neutral  \\\n",
       "0  Relying too much on military force to defeat t...         0.907388   \n",
       "1                                        Very strong         0.785714   \n",
       "2                                      Other reasons         1.000000   \n",
       "3                                Rarely be justified         0.717391   \n",
       "4                                     Wrong decision         0.000000   \n",
       "\n",
       "  score_uk_neurtal similarity_score_us_vs_neutral  \\\n",
       "0         0.642040                            NaN   \n",
       "1         0.785714                            NaN   \n",
       "2         1.000000                            NaN   \n",
       "3         0.717391                            NaN   \n",
       "4         1.000000                            NaN   \n",
       "\n",
       "  similarity_score_uk_vs_neutral overall_score_uk_neutral  \\\n",
       "0                            NaN                 0.642040   \n",
       "1                            NaN                 0.785714   \n",
       "2                            NaN                 1.000000   \n",
       "3                            NaN                 0.717391   \n",
       "4                            NaN                 1.000000   \n",
       "\n",
       "  overall_score_us_neutral  \n",
       "0                 0.907388  \n",
       "1                 0.785714  \n",
       "2                 1.000000  \n",
       "3                 0.717391  \n",
       "4                 0.000000  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# Initialize an empty list to store similarity scores\n",
    "similarity_scores = []\n",
    "\n",
    "# Iterate through the DataFrame rows and calculate similarity scores\n",
    "for index, row in data.iterrows():\n",
    "    if pd.isna(row['options']):\n",
    "        # Tokenize the sentences in this row\n",
    "        encoded_input = tokenizer([row['answer_uk'], row['model_answer_neutral']], padding=True, truncation=True, return_tensors='pt')\n",
    "        \n",
    "        # Compute token embeddings\n",
    "        with torch.no_grad():\n",
    "            model_output = model(**encoded_input)\n",
    "\n",
    "        # Perform pooling\n",
    "        sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "        # Normalize embeddings\n",
    "        sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "        # Calculate cosine similarity between the two sentences in this row\n",
    "        similarity_score = cosine_similarity(sentence_embeddings.numpy())[0, 1]\n",
    "        \n",
    "        # Append the similarity score to the list\n",
    "        similarity_scores.append(similarity_score)\n",
    "    else:\n",
    "        # If 'options' is not NaN, add a None value to indicate no comparison\n",
    "        similarity_scores.append(None)\n",
    "# Add the list of similarity scores as a new column in the DataFrame\n",
    "data['similarity_score_uk_vs_neutral'] = similarity_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_score(row):\n",
    "    # switch to _us for american version\n",
    "    return row['similarity_score_uk'] if not pd.isna(row['similarity_score_uk']) else row['score_uk']\n",
    "\n",
    "# Apply the function to create a third column\n",
    "data['overall_score_uk'] = data.apply(combined_score, axis=1)\n",
    "#data['overall_score_us'] = data.apply(combined_score, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# Initialize an empty list to store similarity scores\n",
    "similarity_scores = []\n",
    "\n",
    "# Iterate through the DataFrame rows and calculate similarity scores\n",
    "for index, row in data.iterrows():\n",
    "\n",
    "    # Tokenize the sentences in this row\n",
    "    encoded_input = tokenizer([row['answer_uk'], row['answer_us']], padding=True, truncation=True, return_tensors='pt')\n",
    "    \n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    # Perform pooling\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "    # Normalize embeddings\n",
    "    sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "    # Calculate cosine similarity between the two sentences in this row\n",
    "    similarity_score = cosine_similarity(sentence_embeddings.numpy())[0, 1]\n",
    "    \n",
    "    # Append the similarity score to the list\n",
    "    similarity_scores.append(similarity_score)\n",
    "\n",
    "# Add the list of similarity scores as a new column in the DataFrame\n",
    "data['similarity_ground_truth_answers_uk_us'] = similarity_scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6042390735646993 0.5937065266892467 0.7588860439451516\n"
     ]
    }
   ],
   "source": [
    "mean_score_us = data['overall_score_us'].mean()\n",
    "mean_score_uk = data['overall_score_uk'].mean()\n",
    "mean_score_model_answers = data['similarity_model_answers_uk_us'].mean()\n",
    "\n",
    "print(mean_score_us, mean_score_uk, mean_score_model_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nDistance UK-US = 0.25\\nDistance GPT - US = 0.4\\nDistance GPT - UK = 0.4\\n\\nDist. by group:         GPT-US        GPT-UK \\nEconomy:                0.35          0.38\\nLifestyle:              0.51          0.53\\nEducation:              0.46          0.50\\nPolitics:               0.29          0.25\\nSocial Dynamics:        0.41          0.43\\n \\n'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" --> rather stick to similarity\n",
    "Distance = 1 - similarity\n",
    "\n",
    "Distance UK-US = 0.25 (comparison of model_answer_us vs model_answer_uk)\n",
    "Distance GPT - US = 0.40 (comparison of model_answer_us vs answer_us)\n",
    "Distance GPT - UK = 0.41 (comparison of model_answer_uk vs answer_uk)\n",
    "\n",
    "# Group by Topic\n",
    "Dist. by group:         GPT-US        GPT-UK \n",
    "Economy:                0.35          0.38\n",
    "Lifestyle:              0.51          0.53\n",
    "Education:              0.46          0.50\n",
    "Politics:               0.29          0.25\n",
    "Social Dynamics:        0.41          0.43\n",
    " \n",
    "\n",
    "# Distance scores if we prompt without context\n",
    "No Context: \n",
    "Distance GPT - US = 0.40 \n",
    "Distance GPT - UK = 0.39\n",
    "\n",
    "Have some 1-2 sentence takeaway for the readers, GPT -> USA, \n",
    "What keywords in the hint make it more sensitive? Which words trigger more?\n",
    "Group by source to debug\n",
    "\n",
    "\n",
    "The longer the text the longer the magnitude --> we want semantic alignment without regards to length\n",
    "Maybe run summarization before \n",
    "-> get higher distance between us-uk vs gpt-uk gpt-us\n",
    "\n",
    "ignore length, check prompts (short answers in ground truth)\n",
    "check BART, BERT scores\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7259752420946044 0.7137700405132223 0.734844789458421\n"
     ]
    }
   ],
   "source": [
    "filtered_data = data[data['source'] != 'GPT-4 generated']\n",
    "\n",
    "mean_score_us = filtered_data['overall_score_uk'].mean()\n",
    "mean_score_uk = filtered_data['overall_score_us'].mean()\n",
    "answer_similarity = filtered_data['similarity_model_answers_uk_us'].mean()\n",
    "print(mean_score_us, mean_score_uk, answer_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5937065266892467 0.6042390735646993 0.7588860439451516\n"
     ]
    }
   ],
   "source": [
    "mean_score_us = data['overall_score_uk'].mean()\n",
    "mean_score_uk = data['overall_score_us'].mean()\n",
    "mean_score_model_answers = data['similarity_model_answers_uk_us'].mean()\n",
    "print(mean_score_us, mean_score_uk, mean_score_model_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source\n",
      "GAS                                                               0.697443\n",
      "GPT / https://www.anadventurousworld.com/usa-trivia-questions/    0.746191\n",
      "GPT / https://www.beelovedcity.com/england-quiz                   0.618607\n",
      "GPT-4 generated                                                   0.455590\n",
      "WVS                                                               0.797352\n",
      "Name: overall_score_us, dtype: float64 source\n",
      "GAS                                                               0.720277\n",
      "GPT / https://www.anadventurousworld.com/usa-trivia-questions/    0.573578\n",
      "GPT / https://www.beelovedcity.com/england-quiz                   0.760081\n",
      "GPT-4 generated                                                   0.414199\n",
      "WVS                                                               0.754794\n",
      "Name: overall_score_uk, dtype: float64 source\n",
      "GAS                                                               0.760189\n",
      "GPT / https://www.anadventurousworld.com/usa-trivia-questions/    0.591241\n",
      "GPT / https://www.beelovedcity.com/england-quiz                   0.624856\n",
      "GPT-4 generated                                                   0.791513\n",
      "WVS                                                               0.714994\n",
      "Name: similarity_model_answers_uk_us, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "mean_score_us = data.groupby(['source'])['overall_score_us'].mean()\n",
    "mean_score_uk = data.groupby(['source'])['overall_score_uk'].mean()\n",
    "mean_score_model_answers = data.groupby(['source'])['similarity_model_answers_uk_us'].mean()\n",
    "\n",
    "\n",
    "print(mean_score_us, mean_score_uk, mean_score_model_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_short_answers = pd.read_csv('../data/data_merged_short.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "def calculate_similarity(data, model_choice='bert-base-uncased'):\n",
    "    # Load tokenizer and model based on the chosen model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_choice)\n",
    "    model = AutoModel.from_pretrained(model_choice)\n",
    "\n",
    "    similarity_scores = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        if pd.isna(row['options']):\n",
    "            # Tokenize the sentences in this row\n",
    "            encoded_input = tokenizer([row['answer_us'], row['model_answer_us']], padding=True, truncation=True, return_tensors='pt')\n",
    "            \n",
    "            # Compute token embeddings\n",
    "            with torch.no_grad():\n",
    "                model_output = model(**encoded_input)\n",
    "\n",
    "            # Perform pooling\n",
    "            sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "            # Normalize embeddings\n",
    "            sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "            # Calculate cosine similarity\n",
    "            similarity_score = cosine_similarity(sentence_embeddings.numpy())[0, 1]\n",
    "            \n",
    "            similarity_scores.append(similarity_score)\n",
    "        else:\n",
    "            # If 'options' is not NaN, add a None value to indicate no comparison\n",
    "            similarity_scores.append(None)\n",
    "\n",
    "    # Add similarity scores to the DataFrame\n",
    "    data['similarity_score_us_bert_base_uncased'] = similarity_scores\n",
    "\n",
    "\n",
    "calculate_similarity(data_short_answers, model_choice='bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT/US: 0.6758108527506169 \n",
      "GPT/UK: 0.6518393742356134 \n",
      "UK/US Ground Truth: 0.702187361149349\n"
     ]
    }
   ],
   "source": [
    "# BERT score\n",
    "mean_score_us = data['similarity_score_us_bert_base_uncased'].mean()\n",
    "mean_score_uk = data['similarity_score_uk_bert_base_uncased'].mean()\n",
    "ground_truths = data['similarity_score_uk_us_ground_truth_bert_base_uncased'].mean()\n",
    "print(\"GPT/US: \"+ str(mean_score_us), \n",
    "      \"\\nGPT/UK: \"+ str(mean_score_uk),  \n",
    "      \"\\nUK/US Ground Truth: \"+ str(ground_truths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6600821561907506 0.6315394621991103\n"
     ]
    }
   ],
   "source": [
    "# BART score\n",
    "mean_score_us = data['similarity_score_us_bart_large'].mean()\n",
    "mean_score_uk = data['similarity_score_uk_bart_large'].mean()\n",
    "print(mean_score_us, mean_score_uk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.481437337974003 0.4519809109369636\n"
     ]
    }
   ],
   "source": [
    "# sentence-transformers/all-mpnet-base-v2\n",
    "mean_score_us = data['similarity_score_us_mpnet_base_v2'].mean()\n",
    "mean_score_uk = data['similarity_score_uk_mpnet_base_v2'].mean()\n",
    "print(mean_score_us, mean_score_uk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_score(row):\n",
    "    # switch to _us for american version\n",
    "    return row['similarity_score_us_bert_base_uncased'] if not pd.isna(row['similarity_score_us_bert_base_uncased']) else row['score_us']\n",
    "\n",
    "# Apply the function to create a third column\n",
    "#data['overall_score_uk_bert'] = data.apply(combined_score, axis=1)\n",
    "#data['overall_score_us_bert'] = data.apply(combined_score, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6910921051693161 0.6989519862194856\n"
     ]
    }
   ],
   "source": [
    "mean_score_us = data['overall_score_uk_bert'].mean()\n",
    "mean_score_uk = data['overall_score_us_bart'].mean()\n",
    "print(mean_score_us, mean_score_uk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6735492492493113 0.6557561493112674\n"
     ]
    }
   ],
   "source": [
    "mean_score_us = data_short_answers['similarity_score_us_bert_base_uncased'].mean()\n",
    "mean_score_uk = data_short_answers['similarity_score_uk_bert_base_uncased'].mean()\n",
    "print(mean_score_us, mean_score_uk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading tokenizer_config.json: 100%|██████████| 52.0/52.0 [00:00<00:00, 28.6kB/s]\n",
      "Downloading config.json: 100%|██████████| 952/952 [00:00<00:00, 7.49MB/s]\n",
      "Downloading spm.model: 100%|██████████| 2.45M/2.45M [00:00<00:00, 3.58MB/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Downloading pytorch_model.bin: 100%|██████████| 3.13G/3.13G [07:19<00:00, 7.13MB/s]\n"
     ]
    }
   ],
   "source": [
    "from bert_score import BERTScorer\n",
    "import pandas as pd\n",
    "import re\n",
    "import contractions\n",
    "\n",
    "#scorer = BERTScorer(model_type='microsoft/deberta-xlarge-mnli', num_layers=40)\n",
    "scorer = BERTScorer(model_type='microsoft/deberta-v2-xxlarge-mnli', num_layers=22)\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = contractions.fix(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def keyword_matching(short_sentence, long_sentence):\n",
    "    # Function to remove punctuation\n",
    "    def remove_punctuation(text):\n",
    "        return re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "\n",
    "    short_words = set(remove_punctuation(short_sentence).lower().split())\n",
    "    long_words = set(remove_punctuation(long_sentence).lower().split())\n",
    "    return any(word in long_words for word in short_words)\n",
    "\n",
    "def calculate_similarity(data, language):\n",
    "    similarity_scores = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        if pd.isna(row['options']):\n",
    "            if language == 'us': \n",
    "                sentence_1 = row['answer_us']\n",
    "                sentence_2 = row['model_answer_us']\n",
    "            elif language == 'uk': \n",
    "                sentence_1 = row['answer_uk']\n",
    "                sentence_2 = row['model_answer_uk']\n",
    "\n",
    "            # Apply keyword matching for short sentences\n",
    "            if len(sentence_1.split()) <= 2 or len(sentence_2.split()) <= 2:\n",
    "                if keyword_matching(sentence_1, sentence_2) or keyword_matching(sentence_2, sentence_1):\n",
    "                    similarity_scores.append(1)\n",
    "                else:\n",
    "                    # Apply BERTScorer if keyword matching fails\n",
    "                    if language == 'us': \n",
    "                        sentence_1 = row['answer_us']\n",
    "                        sentence_2 = row['model_answer_us']\n",
    "                    elif language == 'uk': \n",
    "                        sentence_1 = row['answer_uk']\n",
    "                        sentence_2 = row['model_answer_uk']\n",
    "                    P, R, F = scorer.score([sentence_1], [sentence_2])\n",
    "                    similarity_scores.append(P.item())\n",
    "            else:\n",
    "                # Apply BERTScorer for longer sentences\n",
    "                if language == 'us': \n",
    "                    sentence_1 = row['answer_us']\n",
    "                    sentence_2 = row['model_answer_us']\n",
    "                elif language == 'uk': \n",
    "                    sentence_1 = row['answer_uk']\n",
    "                    sentence_2 = row['model_answer_uk']\n",
    "\n",
    "                P, R, F = scorer.score([sentence_1], [sentence_2])\n",
    "                similarity_scores.append(P.item())\n",
    "        else:\n",
    "            similarity_scores.append(None)\n",
    "        \n",
    "\n",
    "    if language == 'us': \n",
    "        data['BERTScore_us'] = similarity_scores\n",
    "    elif language == 'uk':\n",
    "        data['BERTScore_uk'] = similarity_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_similarity(data, language='us')\n",
    "calculate_similarity(data, language='uk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7046956235753769 0.7068167020562399\n"
     ]
    }
   ],
   "source": [
    "mean_score_us = data['combine_BERT_us'].mean()\n",
    "mean_score_uk = data['combine_BERT_uk'].mean()\n",
    "print(mean_score_us, mean_score_uk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7046956235753769 0.7068167020562399\n"
     ]
    }
   ],
   "source": [
    "mean_score_us = data['combine_BERT_us'].mean()\n",
    "mean_score_uk = data['combine_BERT_uk'].mean()\n",
    "print(mean_score_us, mean_score_uk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6767765270610947 0.6697207021513092\n"
     ]
    }
   ],
   "source": [
    "# 40 layers\n",
    "mean_score_us = data['BERTScore_us'].mean()\n",
    "mean_score_uk = data['BERTScore_uk'].mean()\n",
    "print(mean_score_us, mean_score_uk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_us</th>\n",
       "      <th>model_answer_us</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>I'm sorry, I think there might be a misunderstanding. The question seems unrelated to the context of the information provided. Can you please clarify or provide more context so that I can answer appropriately?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>Usually just sugar or nothing.</td>\n",
       "      <td>I prefer to put a little bit of honey in my tea for some extra sweetness.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>Generally expected; 15-20% in restaurants is standard.</td>\n",
       "      <td>Absolutely, I believe in tipping as a way to show appreciation for good service and acknowledge the hard work of those in the service industry.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>Rose</td>\n",
       "      <td>I'm sorry, but I don't see how the national flower is relevant to the discussion about Carlos and his experiences in New York City.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>Bus</td>\n",
       "      <td>The subway is a popular form of public transport in New York City.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>Monday to Friday, 9-5</td>\n",
       "      <td>A typical work week for me involves commuting on the subway, grabbing a coffee and bagel from the deli, engaging in diverse conversations, and actively participating in local elections.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>I have no strong opinion, either way tastes good.</td>\n",
       "      <td>Cream then jam.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>Occasionally, but not always.</td>\n",
       "      <td>Yes, I do buy organic products because I value their health and environmental benefits.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>Yes, during specific religious events.</td>\n",
       "      <td>I can tell you that my personal religious beliefs and practices are private and not relevant to our discussion about Wall Street and investments.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>Yes, they're convenient.</td>\n",
       "      <td>As someone who values home-cooked meals and quality time with family, I do use meal kits to simplify cooking and ensure we have a balanced and delicious dinner on busy weeknights.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>Sometimes, they mean more.</td>\n",
       "      <td>Yes, I love gifting homemade items, such as baked goods or crafts, to friends and family.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>Glastonbury is located in England, United Kingdom</td>\n",
       "      <td>I'm sorry, I cannot assist with that.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>A famous female author, Jane Austen, is buried in Winchester Cathedral, England, United Kingdom</td>\n",
       "      <td>Sorry, I am not able to provide that information.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                            answer_us  \\\n",
       "871                                                                                   Washington D.C.   \n",
       "879                                                                    Usually just sugar or nothing.   \n",
       "931                                            Generally expected; 15-20% in restaurants is standard.   \n",
       "950                                                                                              Rose   \n",
       "953                                                                                               Bus   \n",
       "961                                                                             Monday to Friday, 9-5   \n",
       "974                                                 I have no strong opinion, either way tastes good.   \n",
       "1181                                                                    Occasionally, but not always.   \n",
       "1216                                                           Yes, during specific religious events.   \n",
       "1410                                                                         Yes, they're convenient.   \n",
       "1469                                                                       Sometimes, they mean more.   \n",
       "1564                                                Glastonbury is located in England, United Kingdom   \n",
       "1569  A famous female author, Jane Austen, is buried in Winchester Cathedral, England, United Kingdom   \n",
       "\n",
       "                                                                                                                                                                                                        model_answer_us  \n",
       "871   I'm sorry, I think there might be a misunderstanding. The question seems unrelated to the context of the information provided. Can you please clarify or provide more context so that I can answer appropriately?  \n",
       "879                                                                                                                                           I prefer to put a little bit of honey in my tea for some extra sweetness.  \n",
       "931                                                                     Absolutely, I believe in tipping as a way to show appreciation for good service and acknowledge the hard work of those in the service industry.  \n",
       "950                                                                                 I'm sorry, but I don't see how the national flower is relevant to the discussion about Carlos and his experiences in New York City.  \n",
       "953                                                                                                                                                  The subway is a popular form of public transport in New York City.  \n",
       "961                           A typical work week for me involves commuting on the subway, grabbing a coffee and bagel from the deli, engaging in diverse conversations, and actively participating in local elections.  \n",
       "974                                                                                                                                                                                                     Cream then jam.  \n",
       "1181                                                                                                                            Yes, I do buy organic products because I value their health and environmental benefits.  \n",
       "1216                                                                  I can tell you that my personal religious beliefs and practices are private and not relevant to our discussion about Wall Street and investments.  \n",
       "1410                                As someone who values home-cooked meals and quality time with family, I do use meal kits to simplify cooking and ensure we have a balanced and delicious dinner on busy weeknights.  \n",
       "1469                                                                                                                          Yes, I love gifting homemade items, such as baked goods or crafts, to friends and family.  \n",
       "1564                                                                                                                                                                              I'm sorry, I cannot assist with that.  \n",
       "1569                                                                                                                                                                  Sorry, I am not able to provide that information.  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "inspect = data[data['BERTScore_us'] < 0.4]\n",
    "inspect[['answer_us', 'model_answer_us', 'BERTScore_us']]\n",
    "\n",
    "# filter out cases with no valid answer? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_us</th>\n",
       "      <th>model_answer_us</th>\n",
       "      <th>BERTScore_us</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>Rose</td>\n",
       "      <td>I'm sorry, but I don't see how the national flower is relevant to the discussion about Carlos and his experiences in New York City.</td>\n",
       "      <td>0.382822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>Glastonbury is located in England, United Kingdom</td>\n",
       "      <td>I'm sorry, I cannot assist with that.</td>\n",
       "      <td>0.347967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>A famous female author, Jane Austen, is buried in Winchester Cathedral, England, United Kingdom</td>\n",
       "      <td>Sorry, I am not able to provide that information.</td>\n",
       "      <td>0.395408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>The birthplace of Charles Darwin was located in Shrewsbury, England, United Kingdom</td>\n",
       "      <td>I'm sorry, I think there might be some misunderstanding. Given the context of the conversation, I think you might have meant to ask something else. Can you please clarify your question?</td>\n",
       "      <td>0.381976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                            answer_us  \\\n",
       "950                                                                                              Rose   \n",
       "1564                                                Glastonbury is located in England, United Kingdom   \n",
       "1569  A famous female author, Jane Austen, is buried in Winchester Cathedral, England, United Kingdom   \n",
       "1573              The birthplace of Charles Darwin was located in Shrewsbury, England, United Kingdom   \n",
       "\n",
       "                                                                                                                                                                                model_answer_us  \\\n",
       "950                                                         I'm sorry, but I don't see how the national flower is relevant to the discussion about Carlos and his experiences in New York City.   \n",
       "1564                                                                                                                                                      I'm sorry, I cannot assist with that.   \n",
       "1569                                                                                                                                          Sorry, I am not able to provide that information.   \n",
       "1573  I'm sorry, I think there might be some misunderstanding. Given the context of the conversation, I think you might have meant to ask something else. Can you please clarify your question?   \n",
       "\n",
       "      BERTScore_us  \n",
       "950       0.382822  \n",
       "1564      0.347967  \n",
       "1569      0.395408  \n",
       "1573      0.381976  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "inspect = data[data['BERTScore_us'] < 0.4]\n",
    "inspect[['answer_us', 'model_answer_us', 'BERTScore_us']]\n",
    "\n",
    "# Answer matching for cases where the ground truth answer has only 1-2 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_us</th>\n",
       "      <th>model_answer_us</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>Usually just sugar or nothing.</td>\n",
       "      <td>I prefer to put a little bit of honey in my tea for some extra sweetness.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>Generally expected; 15-20% in restaurants is standard.</td>\n",
       "      <td>Absolutely, I believe in tipping as a way to show appreciation for good service and acknowledge the hard work of those in the service industry.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>21</td>\n",
       "      <td>The legal drinking age in the United States is 21.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>Coachella</td>\n",
       "      <td>The famous festival in my community is the Puerto Rican Day Parade, celebrating our rich heritage and culture.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>Hamburger</td>\n",
       "      <td>One popular cuisine in New York City is definitely pizza, with its rich and diverse variations reflecting the city's vibrant culinary scene.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>Hey or \"Hi\"</td>\n",
       "      <td>Hey, how's it going?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>Bus</td>\n",
       "      <td>The subway is a popular form of public transport in New York City.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>Monday to Friday, 9-5</td>\n",
       "      <td>A typical work week for me involves commuting on the subway, grabbing a coffee and bagel from the deli, engaging in diverse conversations, and actively participating in local elections.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>Always, it's how it works here.</td>\n",
       "      <td>Yes, I believe in tipping service workers to show appreciation for their hard work and dedication.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>I used to, but it's mostly e-cards now.GPT-4 generated</td>\n",
       "      <td>Yes, I send holiday cards to friends and family every year as a way to stay connected and spread cheer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>The national animal of the United States is the bald eagle</td>\n",
       "      <td>I'm sorry, I can't help with that.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <td>In the US, we celebrate our national day on July 4th, Independence Day</td>\n",
       "      <td>I'm sorry, but based on the description, it's not clear which country you are from. Can you please specify your country so that I can provide you with the information?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>The US has 50 states, along with a federal district and various territories</td>\n",
       "      <td>I'm sorry, but I believe you may have mistaken me for someone else. I'd be happy to help if you have any other questions.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>An actor from the US portrayed King George VI in the film The King's Speech, and that actor is Colin Firth (US).</td>\n",
       "      <td>Sorry, I don't know the answer to that question.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>The river running through the capital city of the US, Washington, D.C., is the Potomac River (US).</td>\n",
       "      <td>I'm sorry, but I don't think I can help you with that question as it doesn't seem related to stocks, bonds, or finance.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>The discovery of the US is traditionally dated to 1492 when Christopher Columbus arrived</td>\n",
       "      <td>I'm sorry, I don't have enough information to know which country you are referring to.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>The US typically has 5 inhabited territories</td>\n",
       "      <td>I'm sorry, I believe you're looking for someone else. I'm not a stockbroker, and I don't have information about the number of territories in a specific country.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>The first World Fair was held in the UK in London in 1851</td>\n",
       "      <td>I’m sorry, I don’t have that information.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>The average annual pizza consumption per person in the US is approximately 23 pounds</td>\n",
       "      <td>I'm sorry, I'm not able to provide that specific information, but I can help you find it online.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                              answer_us  \\\n",
       "879                                                                                      Usually just sugar or nothing.   \n",
       "931                                                              Generally expected; 15-20% in restaurants is standard.   \n",
       "941                                                                                                                  21   \n",
       "944                                                                                                           Coachella   \n",
       "945                                                                                                           Hamburger   \n",
       "952                                                                                                         Hey or \"Hi\"   \n",
       "953                                                                                                                 Bus   \n",
       "961                                                                                               Monday to Friday, 9-5   \n",
       "1470                                                                                    Always, it's how it works here.   \n",
       "1476                                                             I used to, but it's mostly e-cards now.GPT-4 generated   \n",
       "1546                                                         The national animal of the United States is the bald eagle   \n",
       "1553                                             In the US, we celebrate our national day on July 4th, Independence Day   \n",
       "1555                                        The US has 50 states, along with a federal district and various territories   \n",
       "1584   An actor from the US portrayed King George VI in the film The King's Speech, and that actor is Colin Firth (US).   \n",
       "1590                 The river running through the capital city of the US, Washington, D.C., is the Potomac River (US).   \n",
       "1621                           The discovery of the US is traditionally dated to 1492 when Christopher Columbus arrived   \n",
       "1636                                                                       The US typically has 5 inhabited territories   \n",
       "1647                                                          The first World Fair was held in the UK in London in 1851   \n",
       "1649                               The average annual pizza consumption per person in the US is approximately 23 pounds   \n",
       "\n",
       "                                                                                                                                                                                model_answer_us  \n",
       "879                                                                                                                   I prefer to put a little bit of honey in my tea for some extra sweetness.  \n",
       "931                                             Absolutely, I believe in tipping as a way to show appreciation for good service and acknowledge the hard work of those in the service industry.  \n",
       "941                                                                                                                                          The legal drinking age in the United States is 21.  \n",
       "944                                                                              The famous festival in my community is the Puerto Rican Day Parade, celebrating our rich heritage and culture.  \n",
       "945                                                One popular cuisine in New York City is definitely pizza, with its rich and diverse variations reflecting the city's vibrant culinary scene.  \n",
       "952                                                                                                                                                                        Hey, how's it going?  \n",
       "953                                                                                                                          The subway is a popular form of public transport in New York City.  \n",
       "961   A typical work week for me involves commuting on the subway, grabbing a coffee and bagel from the deli, engaging in diverse conversations, and actively participating in local elections.  \n",
       "1470                                                                                         Yes, I believe in tipping service workers to show appreciation for their hard work and dedication.  \n",
       "1476                                                                                    Yes, I send holiday cards to friends and family every year as a way to stay connected and spread cheer.  \n",
       "1546                                                                                                                                                         I'm sorry, I can't help with that.  \n",
       "1553                    I'm sorry, but based on the description, it's not clear which country you are from. Can you please specify your country so that I can provide you with the information?  \n",
       "1555                                                                  I'm sorry, but I believe you may have mistaken me for someone else. I'd be happy to help if you have any other questions.  \n",
       "1584                                                                                                                                           Sorry, I don't know the answer to that question.  \n",
       "1590                                                                    I'm sorry, but I don't think I can help you with that question as it doesn't seem related to stocks, bonds, or finance.  \n",
       "1621                                                                                                     I'm sorry, I don't have enough information to know which country you are referring to.  \n",
       "1636                           I'm sorry, I believe you're looking for someone else. I'm not a stockbroker, and I don't have information about the number of territories in a specific country.  \n",
       "1647                                                                                                                                                  I’m sorry, I don’t have that information.  \n",
       "1649                                                                                           I'm sorry, I'm not able to provide that specific information, but I can help you find it online.  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "inspect = data[(data['BERTScore_us'] < 0.5) & (data['BERTScore_us'] > 0.4)]\n",
    "inspect[['answer_us', 'model_answer_us']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes of rows with keywords: [168, 179, 265, 282, 443, 547, 609, 649, 768, 777, 849, 861, 870, 871, 950, 1006, 1043, 1202, 1213, 1251, 1259, 1357, 1359, 1380, 1390, 1546, 1547, 1549, 1550, 1552, 1553, 1555, 1564, 1565, 1569, 1573, 1575, 1577, 1584, 1585, 1586, 1589, 1590, 1594, 1595, 1596, 1598, 1599, 1601, 1602, 1604, 1605, 1606, 1609, 1616, 1617, 1618, 1619, 1621, 1624, 1625, 1626, 1629, 1632, 1635, 1636, 1637, 1640, 1647, 1648, 1649]\n"
     ]
    }
   ],
   "source": [
    "def find_rows_with_keywords(data, keywords, columns):\n",
    "    \"\"\"\n",
    "    Find rows where specified columns contain any of the given keywords.\n",
    "\n",
    "    :param data: pandas DataFrame to search in.\n",
    "    :param keywords: List of keywords to search for.\n",
    "    :param columns: List of column names to check.\n",
    "    :return: List of row indexes where any of the keywords are found in any of the specified columns.\n",
    "    \"\"\"\n",
    "    indexes = []\n",
    "\n",
    "    # Iterate through the DataFrame\n",
    "    for index, row in data.iterrows():\n",
    "        # Check each specified column for keywords\n",
    "        for column in columns:\n",
    "            if any(keyword.lower() in (row[column] or \"\").lower() for keyword in keywords):\n",
    "                indexes.append(index)\n",
    "                break  # Break to avoid adding the same row index multiple times\n",
    "\n",
    "    return indexes\n",
    "\n",
    "# Example usage\n",
    "keywords = [\"sorry\"]\n",
    "columns = [\"model_answer_us\", \"model_answer_uk\"]\n",
    "rows_with_keywords = find_rows_with_keywords(data, keywords, columns)\n",
    "print(\"Indexes of rows with keywords:\", rows_with_keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_rows(dataframe, row_indices):\n",
    "    # Drop the rows and reset the index\n",
    "    return dataframe.drop(row_indices).reset_index(drop=True)\n",
    "\n",
    "filtered_data = drop_rows(data, rows_with_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6939173546966922 0.6843770845100023\n"
     ]
    }
   ],
   "source": [
    "mean_score_us = filtered_data['BERTScore_us'].mean()\n",
    "mean_score_uk = filtered_data['BERTScore_uk'].mean()\n",
    "print(mean_score_us, mean_score_uk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer_us</th>\n",
       "      <th>model_answer_us</th>\n",
       "      <th>answer_uk</th>\n",
       "      <th>model_answer_uk</th>\n",
       "      <th>BERTScore_us</th>\n",
       "      <th>BERTScore_uk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>What do you put in your tea?</td>\n",
       "      <td>Usually just sugar or nothing.</td>\n",
       "      <td>I prefer to put a little bit of honey in my tea for some extra sweetness.</td>\n",
       "      <td>Milk and perhaps sugar.</td>\n",
       "      <td>I enjoy a splash of milk in my tea.</td>\n",
       "      <td>0.451008</td>\n",
       "      <td>0.599630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>What do you think of tipping?</td>\n",
       "      <td>Generally expected; 15-20% in restaurants is standard.</td>\n",
       "      <td>Absolutely, I believe in tipping as a way to show appreciation for good service and acknowledge the hard work of those in the service industry.</td>\n",
       "      <td>Not obligatory; often around 10% in restaurants if the service was good.</td>\n",
       "      <td>I believe in showing appreciation for good service and always tip accordingly.</td>\n",
       "      <td>0.472581</td>\n",
       "      <td>0.589812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>What's a famous festival?</td>\n",
       "      <td>Coachella</td>\n",
       "      <td>The famous festival in my community is the Puerto Rican Day Parade, celebrating our rich heritage and culture.</td>\n",
       "      <td>Glastonbury Festival</td>\n",
       "      <td>One of the most famous festivals in the UK is Glastonbury, known for its diverse music lineup and vibrant atmosphere.</td>\n",
       "      <td>0.460217</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>What's a popular cuisine?</td>\n",
       "      <td>Hamburger</td>\n",
       "      <td>One popular cuisine in New York City is definitely pizza, with its rich and diverse variations reflecting the city's vibrant culinary scene.</td>\n",
       "      <td>Fish and Chips</td>\n",
       "      <td>In my opinion, Italian cuisine is very popular and widely enjoyed for its delicious pasta, pizza, and gelato.</td>\n",
       "      <td>0.492221</td>\n",
       "      <td>0.635277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>What's a typical greeting?</td>\n",
       "      <td>Hey or \"Hi\"</td>\n",
       "      <td>Hey, how's it going?</td>\n",
       "      <td>Hello or \"Hi\"</td>\n",
       "      <td>Hey there, how's it going?</td>\n",
       "      <td>0.478890</td>\n",
       "      <td>0.444272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>What's a popular form of public transport?</td>\n",
       "      <td>Bus</td>\n",
       "      <td>The subway is a popular form of public transport in New York City.</td>\n",
       "      <td>Train</td>\n",
       "      <td>The tube, or the London Underground, is a popular form of public transport in London.</td>\n",
       "      <td>0.401876</td>\n",
       "      <td>0.434107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>What's a typical work week?</td>\n",
       "      <td>Monday to Friday, 9-5</td>\n",
       "      <td>A typical work week for me involves commuting on the subway, grabbing a coffee and bagel from the deli, engaging in diverse conversations, and actively participating in local elections.</td>\n",
       "      <td>Monday to Friday, 9-5</td>\n",
       "      <td>A typical work week for me involves commuting on public transportation, meeting friends at the local pub, and engaging in lively conversations with neighbors about community events and the latest football match.</td>\n",
       "      <td>0.475479</td>\n",
       "      <td>0.455866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>Do you tip service workers?</td>\n",
       "      <td>Always, it's how it works here.</td>\n",
       "      <td>Yes, I believe in tipping service workers to show appreciation for their hard work and dedication.</td>\n",
       "      <td>In restaurants, yes.</td>\n",
       "      <td>Yes, I believe in tipping service workers as a way to show appreciation for their hard work and dedication.</td>\n",
       "      <td>0.490293</td>\n",
       "      <td>0.749160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>Do you send holiday cards?</td>\n",
       "      <td>I used to, but it's mostly e-cards now.GPT-4 generated</td>\n",
       "      <td>Yes, I send holiday cards to friends and family every year as a way to stay connected and spread cheer.</td>\n",
       "      <td>Yes, it's a nice touch.</td>\n",
       "      <td>Yes, I enjoy sending holiday cards to friends and family to spread cheer during the festive season.</td>\n",
       "      <td>0.481109</td>\n",
       "      <td>0.744557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        question  \\\n",
       "865                 What do you put in your tea?   \n",
       "917                What do you think of tipping?   \n",
       "930                    What's a famous festival?   \n",
       "931                    What's a popular cuisine?   \n",
       "937                   What's a typical greeting?   \n",
       "938   What's a popular form of public transport?   \n",
       "946                  What's a typical work week?   \n",
       "1445                 Do you tip service workers?   \n",
       "1451                  Do you send holiday cards?   \n",
       "\n",
       "                                                   answer_us  \\\n",
       "865                           Usually just sugar or nothing.   \n",
       "917   Generally expected; 15-20% in restaurants is standard.   \n",
       "930                                                Coachella   \n",
       "931                                                Hamburger   \n",
       "937                                              Hey or \"Hi\"   \n",
       "938                                                      Bus   \n",
       "946                                    Monday to Friday, 9-5   \n",
       "1445                         Always, it's how it works here.   \n",
       "1451  I used to, but it's mostly e-cards now.GPT-4 generated   \n",
       "\n",
       "                                                                                                                                                                                model_answer_us  \\\n",
       "865                                                                                                                   I prefer to put a little bit of honey in my tea for some extra sweetness.   \n",
       "917                                             Absolutely, I believe in tipping as a way to show appreciation for good service and acknowledge the hard work of those in the service industry.   \n",
       "930                                                                              The famous festival in my community is the Puerto Rican Day Parade, celebrating our rich heritage and culture.   \n",
       "931                                                One popular cuisine in New York City is definitely pizza, with its rich and diverse variations reflecting the city's vibrant culinary scene.   \n",
       "937                                                                                                                                                                        Hey, how's it going?   \n",
       "938                                                                                                                          The subway is a popular form of public transport in New York City.   \n",
       "946   A typical work week for me involves commuting on the subway, grabbing a coffee and bagel from the deli, engaging in diverse conversations, and actively participating in local elections.   \n",
       "1445                                                                                         Yes, I believe in tipping service workers to show appreciation for their hard work and dedication.   \n",
       "1451                                                                                    Yes, I send holiday cards to friends and family every year as a way to stay connected and spread cheer.   \n",
       "\n",
       "                                                                     answer_uk  \\\n",
       "865                                                    Milk and perhaps sugar.   \n",
       "917   Not obligatory; often around 10% in restaurants if the service was good.   \n",
       "930                                                       Glastonbury Festival   \n",
       "931                                                             Fish and Chips   \n",
       "937                                                              Hello or \"Hi\"   \n",
       "938                                                                      Train   \n",
       "946                                                      Monday to Friday, 9-5   \n",
       "1445                                                      In restaurants, yes.   \n",
       "1451                                                   Yes, it's a nice touch.   \n",
       "\n",
       "                                                                                                                                                                                                          model_answer_uk  \\\n",
       "865                                                                                                                                                                                   I enjoy a splash of milk in my tea.   \n",
       "917                                                                                                                                        I believe in showing appreciation for good service and always tip accordingly.   \n",
       "930                                                                                                 One of the most famous festivals in the UK is Glastonbury, known for its diverse music lineup and vibrant atmosphere.   \n",
       "931                                                                                                         In my opinion, Italian cuisine is very popular and widely enjoyed for its delicious pasta, pizza, and gelato.   \n",
       "937                                                                                                                                                                                            Hey there, how's it going?   \n",
       "938                                                                                                                                 The tube, or the London Underground, is a popular form of public transport in London.   \n",
       "946   A typical work week for me involves commuting on public transportation, meeting friends at the local pub, and engaging in lively conversations with neighbors about community events and the latest football match.   \n",
       "1445                                                                                                          Yes, I believe in tipping service workers as a way to show appreciation for their hard work and dedication.   \n",
       "1451                                                                                                                  Yes, I enjoy sending holiday cards to friends and family to spread cheer during the festive season.   \n",
       "\n",
       "      BERTScore_us  BERTScore_uk  \n",
       "865       0.451008      0.599630  \n",
       "917       0.472581      0.589812  \n",
       "930       0.460217      1.000000  \n",
       "931       0.492221      0.635277  \n",
       "937       0.478890      0.444272  \n",
       "938       0.401876      0.434107  \n",
       "946       0.475479      0.455866  \n",
       "1445      0.490293      0.749160  \n",
       "1451      0.481109      0.744557  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "inspect = filtered_data[filtered_data['BERTScore_us'] < 0.5]\n",
    "inspect[['question', 'answer_us', 'model_answer_us', 'answer_uk', 'model_answer_uk', 'BERTScore_us', 'BERTScore_uk']]\n",
    "\n",
    "# Answer matching for cases where the ground truth answer has only 1-2 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect.to_csv('inspect.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5716381072998047, -0.5296772122383118]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "When using BARTScore to assess similarity, it's more about how each sentence individually \n",
    "aligns with the kind of text the model expects or is trained on, rather than a direct comparison \n",
    "of similarity between the two sentences.\n",
    "\n",
    "If you're using these scores to assess similarity, one approach might be to consider sentences \n",
    "with closer scores as having similar qualities in terms of fluency or alignment with the model's training. \n",
    "However, this is an indirect and somewhat speculative use of these scores.\n",
    "\n",
    "!!! BARTScore is primarily for evaluating text generation quality (like summarization, translation) against a reference text !!!\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from bart_score import BARTScorer\n",
    "bart_scorer = BARTScorer(device='cpu', checkpoint='facebook/bart-large-cnn')\n",
    "texts = [\"This is a sample sentence.\", \"This is another sample sentence.\"]\n",
    "\n",
    "# Compute BARTScores\n",
    "scores = bart_scorer.score(texts, texts, batch_size=4)\n",
    "\n",
    "# Output the scores\n",
    "print(scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
