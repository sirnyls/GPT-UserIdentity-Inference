{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/dataset_merged.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'question', 'selections', 'options', 'options_formatted',\n",
       "       'source', 'value_us', 'value_uk', 'answer_us', 'answer_uk', 'category',\n",
       "       '# of options', 'question type', 'category_group', 'model_answer_us',\n",
       "       'model_answer_uk', 'model_answer_uk_option_match',\n",
       "       'model_answer_us_option_match', '#_options', 'score_uk', 'score_us',\n",
       "       'overall_score_uk', 'similarity_score_uk', 'similarity_score_us',\n",
       "       'overall_score_us', 'similarity_model_answers_uk_us',\n",
       "       'similarity_ground_truth_answers_uk_us', 'options_dict',\n",
       "       'score_ground_truth_answers', 'value_diff'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "GAS                                                               303\n",
       "GPT / https://www.anadventurousworld.com/usa-trivia-questions/     14\n",
       "GPT / https://www.beelovedcity.com/england-quiz                    33\n",
       "GPT-4 generated                                                   567\n",
       "WVS                                                                84\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['source'].value_counts().sort_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category_group\n",
       "Economy, Health, and Environment              178\n",
       "Lifestyle, Entertainment, and Daily Living    285\n",
       "Media, Technology, and Education              141\n",
       "Politics and Governance                       206\n",
       "Society, Culture, and Relationships           191\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category_group'].value_counts().sort_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question type\n",
       "Binary Choice      475\n",
       "Likert Scale       292\n",
       "Multiple Choice    131\n",
       "Numerical Scale     18\n",
       "Ordinal Scale       38\n",
       "Quiz question       47\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['question type'].value_counts().sort_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity GPT-US: 0.7404109597490045 \n",
      "Similarity GPT-UK: 0.7113406496108827 \n",
      "Similarity UK-US: 0.6650837094272428\n",
      "Number of q,a,a triples: 1002\n"
     ]
    }
   ],
   "source": [
    "mean_score_ground_truths = df['similarity_ground_truth_answers_uk_us'].mean()\n",
    "mean_score_us = df['overall_score_us'].mean()\n",
    "mean_score_uk = df['overall_score_uk'].mean()\n",
    "print(\"Similarity GPT-US: \" + str(mean_score_us), \n",
    "      \"\\nSimilarity GPT-UK: \" + str(mean_score_uk), \n",
    "      \"\\nSimilarity UK-US: \" + str(mean_score_ground_truths))\n",
    "print(\"Number of q,a,a triples: \" + str(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. number of words per question: 16.803393213572853\n",
      "Avg. number of words per answer: 4.389720558882235\n",
      "Unique words dataset: 2754\n",
      "GOQA - Avg. number of words per question: 32.88113695090439\n",
      "GOQA - Avg. number of words per answer: 3.4702842377260983\n",
      "GOQA - Unique words dataset: 1757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tq/vxytrqv13kx3fp71v2wgtd000000gn/T/ipykernel_69466/1944696797.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = df[column_name].astype(str)\n",
      "/var/folders/tq/vxytrqv13kx3fp71v2wgtd000000gn/T/ipykernel_69466/1944696797.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = df[column_name].astype(str)\n",
      "/var/folders/tq/vxytrqv13kx3fp71v2wgtd000000gn/T/ipykernel_69466/1944696797.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = df[column_name].astype(str)\n",
      "/var/folders/tq/vxytrqv13kx3fp71v2wgtd000000gn/T/ipykernel_69466/2364260934.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = df[column_name].astype(str)\n"
     ]
    }
   ],
   "source": [
    "print(\"Avg. number of words per question: \" + str(average_word_count(df, 'question')))\n",
    "print(\"Avg. number of words per answer: \" + str((average_word_count(df, 'answer_us') + average_word_count(df, 'answer_uk')) / 2))\n",
    "print(\"Unique words dataset: \" + str(unique_word_count(df, 'question')))\n",
    "\n",
    "print(\"GOQA - Avg. number of words per question: \" + str(average_word_count(goqa, 'question')))\n",
    "print(\"GOQA - Avg. number of words per answer: \" + str((average_word_count(goqa, 'answer_us') + average_word_count(goqa, 'answer_uk')) / 2))\n",
    "print(\"GOQA - Unique words dataset: \" + str(unique_word_count(goqa, 'question')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_word_count(df, column_name):\n",
    "    # Convert the column to strings\n",
    "    df[column_name] = df[column_name].astype(str)\n",
    "    # Calculate the number of words for each row in the column\n",
    "    word_counts = df[column_name].apply(lambda x: len(x.split()))\n",
    "    # Return the average word count\n",
    "    return word_counts.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_word_count(df, column_name):\n",
    "\n",
    "    # Convert the column to strings\n",
    "    df[column_name] = df[column_name].astype(str)\n",
    "    # Collect all words from each row in the column\n",
    "    all_words = df[column_name].apply(lambda x: x.split()).explode()\n",
    "\n",
    "    # Count unique words\n",
    "    unique_words = set(all_words)\n",
    "\n",
    "    return len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_values(value):\n",
    "    # Check if value is an integer or greater than 1\n",
    "    if value > 1 or isinstance(value, int):\n",
    "        return value / 1000\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "# Apply the correction function to the column\n",
    "df['similarity_ground_truth_answers_uk_us'] = df['similarity_ground_truth_answers_uk_us'].apply(correct_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity GPT-US: 0.7832165178588248 \n",
      "Similarity GPT-UK: 0.7346302110576967 \n",
      "Similarity UK-US: 0.6852913584027972\n",
      "Number of q,a,a triples: 567\n"
     ]
    }
   ],
   "source": [
    "gpt_generated = df[df['source'] == 'GPT-4 generated']\n",
    "mean_score_ground_truths = gpt_generated['similarity_ground_truth_answers_uk_us'].mean()\n",
    "mean_score_us = gpt_generated['overall_score_us'].mean()\n",
    "mean_score_uk = gpt_generated['overall_score_uk'].mean()\n",
    "print(\"Similarity GPT-US: \" + str(mean_score_us), \n",
    "      \"\\nSimilarity GPT-UK: \" + str(mean_score_uk), \n",
    "      \"\\nSimilarity UK-US: \" + str(mean_score_ground_truths))\n",
    "print(\"Number of q,a,a triples: \" + str(len(gpt_generated)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity GPT-US: 0.6705235090639714 \n",
      "Similarity GPT-UK: 0.6599592853051901 \n",
      "Similarity UK-US: 0.6308118451079614\n",
      "Number of q,a,a triples: 387\n"
     ]
    }
   ],
   "source": [
    "goqa = df[(df['source'] == 'GAS') | (df['source'] == 'WVS')]\n",
    "mean_score_ground_truths = goqa['similarity_ground_truth_answers_uk_us'].mean()\n",
    "mean_score_us = goqa['overall_score_us'].mean()\n",
    "mean_score_uk = goqa['overall_score_uk'].mean()\n",
    "print(\"Similarity GPT-US: \" + str(mean_score_us), \n",
    "      \"\\nSimilarity GPT-UK: \" + str(mean_score_uk), \n",
    "      \"\\nSimilarity UK-US: \" + str(mean_score_ground_truths))\n",
    "print(\"Number of q,a,a triples: \" + str(len(goqa)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity GPT-US: 0.8017642517039116 \n",
      "Similarity GPT-UK: 0.8564725924045482 \n",
      "Similarity UK-US: 0.7081266597230383\n",
      "Number of q,a,a triples: 47\n"
     ]
    }
   ],
   "source": [
    "quiz = df[(df['source'] == 'GPT / https://www.beelovedcity.com/england-quiz') | (df['source'] == 'GPT / https://www.anadventurousworld.com/usa-trivia-questions/')]\n",
    "mean_score_ground_truths = quiz['similarity_ground_truth_answers_uk_us'].mean()\n",
    "mean_score_us = quiz['overall_score_us'].mean()\n",
    "mean_score_uk = quiz['overall_score_uk'].mean()\n",
    "print(\"Similarity GPT-US: \" + str(mean_score_us), \n",
    "      \"\\nSimilarity GPT-UK: \" + str(mean_score_uk), \n",
    "      \"\\nSimilarity UK-US: \" + str(mean_score_ground_truths))\n",
    "print(\"Number of q,a,a triples: \" + str(len(quiz)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
