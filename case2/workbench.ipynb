{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "data = pd.read_csv('essay_prompts.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "linguistic sophistication. \n",
    "Text quality. \n",
    "Factuality. \n",
    "Grammatical mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/nils/GPT-UserIdentity-Inference/case2/workbench.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nils/GPT-UserIdentity-Inference/case2/workbench.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m doc2 \u001b[39m=\u001b[39m nlp(essay2)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nils/GPT-UserIdentity-Inference/case2/workbench.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Analyze linguistic sophistication\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nils/GPT-UserIdentity-Inference/case2/workbench.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m readability1 \u001b[39m=\u001b[39m textstat\u001b[39m.\u001b[39;49mflesch_reading_ease(doc1)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nils/GPT-UserIdentity-Inference/case2/workbench.ipynb#W3sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m readability2 \u001b[39m=\u001b[39m textstat\u001b[39m.\u001b[39mflesch_reading_ease(doc2)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nils/GPT-UserIdentity-Inference/case2/workbench.ipynb#W3sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Add more analysis as needed\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.10/site-packages/textstat/textstat.py:674\u001b[0m, in \u001b[0;36mtextstatistics.flesch_reading_ease\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39m@lru_cache\u001b[39m(maxsize\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m)\n\u001b[1;32m    673\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflesch_reading_ease\u001b[39m(\u001b[39mself\u001b[39m, text: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[0;32m--> 674\u001b[0m     sentence_length \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mavg_sentence_length(text)\n\u001b[1;32m    675\u001b[0m     s_interval \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_lang_root() \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mes\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mit\u001b[39m\u001b[39m'\u001b[39m] \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     syllables_per_word \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavg_syllables_per_word(text, s_interval)\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.10/site-packages/textstat/textstat.py:400\u001b[0m, in \u001b[0;36mtextstatistics.avg_sentence_length\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calculate the average sentence length.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \n\u001b[1;32m    385\u001b[0m \u001b[39mThis function is a combination of the functions `lexicon_count` and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m \n\u001b[1;32m    398\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 400\u001b[0m     asl \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlexicon_count(text) \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentence_count(text))\n\u001b[1;32m    401\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_legacy_round(asl, \u001b[39m1\u001b[39m)\n\u001b[1;32m    402\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mZeroDivisionError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.10/site-packages/textstat/textstat.py:295\u001b[0m, in \u001b[0;36mtextstatistics.lexicon_count\u001b[0;34m(self, text, removepunct)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Count types (words) in a text.\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \n\u001b[1;32m    275\u001b[0m \u001b[39mIf `removepunct` is set to True and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    292\u001b[0m \n\u001b[1;32m    293\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[39mif\u001b[39;00m removepunct:\n\u001b[0;32m--> 295\u001b[0m     text \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mremove_punctuation(text)\n\u001b[1;32m    296\u001b[0m count \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(text\u001b[39m.\u001b[39msplit())\n\u001b[1;32m    297\u001b[0m \u001b[39mreturn\u001b[39;00m count\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.10/site-packages/textstat/textstat.py:268\u001b[0m, in \u001b[0;36mtextstatistics.remove_punctuation\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[39m# remove all punctuation except apostrophes\u001b[39;00m\n\u001b[1;32m    266\u001b[0m     punctuation_regex \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[^\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m'\u001b[39m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 268\u001b[0m text \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39;49msub(punctuation_regex, \u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m, text)\n\u001b[1;32m    269\u001b[0m \u001b[39mreturn\u001b[39;00m text\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.10/re.py:209\u001b[0m, in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msub\u001b[39m(pattern, repl, string, count\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, flags\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m    203\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the string obtained by replacing the leftmost\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39m    non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[39m    replacement repl.  repl can be either a string or a callable;\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39m    if a string, backslash escapes in it are processed.  If it is\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39m    a callable, it's passed the Match object and must return\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[39m    a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m     \u001b[39mreturn\u001b[39;00m _compile(pattern, flags)\u001b[39m.\u001b[39;49msub(repl, string, count)\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "import textstat\n",
    "import spacy\n",
    "import language_tool_python\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy.cli\n",
    "\n",
    "# Load your essays\n",
    "essay1 = data.iloc[0, 5]\n",
    "essay2 = data.iloc[0, 6]\n",
    "\n",
    "# Preprocess (example with spaCy)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc1 = nlp(essay1)\n",
    "doc2 = nlp(essay2)\n",
    "\n",
    "# Analyze linguistic sophistication\n",
    "readability1 = textstat.flesch_reading_ease(essay1)\n",
    "readability2 = textstat.flesch_reading_ease(essay2)\n",
    "\n",
    "\n",
    "\n",
    "# Add more analysis as needed\n",
    "\n",
    "print (\"Readability:\", readability1, readability2)\n",
    "print (\"Errors:\", errors1, errors2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
